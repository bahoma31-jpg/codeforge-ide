/**
 * CodeForge IDE â€” LLM Types & Model Registry
 * Defines all available Groq models with metadata.
 *
 * 14 models across 4 categories:
 * - Text Generation (9): Chat & code completion
 * - Compound AI (2): Multi-step reasoning
 * - Audio STT (2): Speech-to-text
 * - Audio TTS (1): Text-to-speech (Arabic)
 */

// â”€â”€â”€ Model Types â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export type ModelType = 'text' | 'compound' | 'stt' | 'tts';

export interface GroqModel {
  id: string;
  name: string;
  nameAr: string;
  type: ModelType;
  contextWindow: number;
  maxOutputTokens: number;
  description: string;
  descriptionAr: string;
  speed: 'instant' | 'fast' | 'medium' | 'slow';
  quality: 'high' | 'medium' | 'low';
  recommended?: boolean;
}

export interface ModelGroup {
  type: ModelType;
  label: string;
  labelAr: string;
  icon: string;
  models: GroqModel[];
}

// â”€â”€â”€ Chat Message Types â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export type ChatRole = 'system' | 'user' | 'assistant' | 'tool';

export interface ChatMessage {
  role: ChatRole;
  content: string;
  name?: string;
}

export interface ChatCompletionRequest {
  model: string;
  messages: ChatMessage[];
  temperature?: number;
  max_tokens?: number;
  top_p?: number;
  stream?: boolean;
  stop?: string[];
}

export interface ChatCompletionChoice {
  index: number;
  message: ChatMessage;
  finish_reason: 'stop' | 'length' | 'tool_calls' | null;
}

export interface ChatCompletionResponse {
  id: string;
  object: string;
  created: number;
  model: string;
  choices: ChatCompletionChoice[];
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

export interface StreamDelta {
  role?: ChatRole;
  content?: string;
}

export interface StreamChunk {
  id: string;
  object: string;
  created: number;
  model: string;
  choices: Array<{
    index: number;
    delta: StreamDelta;
    finish_reason: 'stop' | 'length' | null;
  }>;
}

// â”€â”€â”€ Provider Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export interface GroqConfig {
  apiKey: string;
  baseUrl?: string;
  defaultModel?: string;
  temperature?: number;
  maxTokens?: number;
}

// â”€â”€â”€ OODA Integration Types â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export interface OODAAnalysisRequest {
  phase: 'observe' | 'orient' | 'decide';
  issue: string;
  fileContents: Record<string, string>;
  context?: string;
}

export interface OODAAnalysisResponse {
  analysis: string;
  suggestions: string[];
  fixes?: Array<{
    filePath: string;
    type: 'edit' | 'rewrite';
    oldStr?: string;
    newStr?: string;
    content?: string;
    explanation: string;
  }>;
  confidence: number;
}

// â”€â”€â”€ All Available Groq Models â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export const GROQ_MODELS: GroqModel[] = [
  // â•â•â• Text Generation Models â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  {
    id: 'llama-3.1-8b-instant',
    name: 'Llama 3.1 8B Instant',
    nameAr: 'Ù„Ø§Ù…Ø§ 3.1 â€” 8B Ø³Ø±ÙŠØ¹',
    type: 'text',
    contextWindow: 131072,
    maxOutputTokens: 8192,
    description: 'Fast & lightweight. Great for quick tasks and prototyping.',
    descriptionAr: 'Ø³Ø±ÙŠØ¹ ÙˆØ®ÙÙŠÙ. Ù…Ø«Ø§Ù„ÙŠ Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø³Ø±ÙŠØ¹Ø© ÙˆØ§Ù„ØªØ¬Ø±ÙŠØ¨.',
    speed: 'instant',
    quality: 'medium',
  },
  {
    id: 'llama-3.3-70b-versatile',
    name: 'Llama 3.3 70B Versatile',
    nameAr: 'Ù„Ø§Ù…Ø§ 3.3 â€” 70B Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…Ù‡Ø§Ù…',
    type: 'text',
    contextWindow: 131072,
    maxOutputTokens: 32768,
    description: 'Balanced power & speed. Best all-around model for coding.',
    descriptionAr: 'ØªÙˆØ§Ø²Ù† Ø¨ÙŠÙ† Ø§Ù„Ù‚ÙˆØ© ÙˆØ§Ù„Ø³Ø±Ø¹Ø©. Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬ Ø´Ø§Ù…Ù„ Ù„Ù„Ø¨Ø±Ù…Ø¬Ø©.',
    speed: 'fast',
    quality: 'high',
    recommended: true,
  },
  {
    id: 'meta-llama/llama-4-scout-17b-16e-instruct',
    name: 'Llama 4 Scout 17B',
    nameAr: 'Ù„Ø§Ù…Ø§ 4 Ø³ÙƒØ§ÙˆØª â€” 17B',
    type: 'text',
    contextWindow: 131072,
    maxOutputTokens: 16384,
    description: 'Next-gen Llama 4 with 16 experts. Excellent for analysis.',
    descriptionAr: 'Ø§Ù„Ø¬ÙŠÙ„ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù„Ø§Ù…Ø§ 4 Ù…Ø¹ 16 Ø®Ø¨ÙŠØ±Ù‹Ø§. Ù…Ù…ØªØ§Ø² Ù„Ù„ØªØ­Ù„ÙŠÙ„.',
    speed: 'fast',
    quality: 'high',
  },
  {
    id: 'meta-llama/llama-4-maverick-17b-128e-instruct',
    name: 'Llama 4 Maverick 17B',
    nameAr: 'Ù„Ø§Ù…Ø§ 4 Ù…Ø§ÙØ±ÙŠÙƒ â€” 17B',
    type: 'text',
    contextWindow: 131072,
    maxOutputTokens: 16384,
    description: 'Llama 4 with 128 experts MoE. Top-tier for complex code tasks.',
    descriptionAr: 'Ù„Ø§Ù…Ø§ 4 Ù…Ø¹ 128 Ø®Ø¨ÙŠØ±Ù‹Ø§. Ø§Ù„Ø£ÙØ¶Ù„ Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©.',
    speed: 'medium',
    quality: 'high',
    recommended: true,
  },
  {
    id: 'openai/gpt-oss-120b',
    name: 'GPT OSS 120B',
    nameAr: 'GPT Ù…ÙØªÙˆØ­ Ø§Ù„Ù…ØµØ¯Ø± â€” 120B',
    type: 'text',
    contextWindow: 131072,
    maxOutputTokens: 16384,
    description: 'OpenAI open-source 120B. Very powerful for deep reasoning.',
    descriptionAr: 'Ù†Ù…ÙˆØ°Ø¬ OpenAI Ù…ÙØªÙˆØ­ Ø§Ù„Ù…ØµØ¯Ø± 120B. Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…ÙŠÙ‚.',
    speed: 'slow',
    quality: 'high',
  },
  {
    id: 'openai/gpt-oss-20b',
    name: 'GPT OSS 20B',
    nameAr: 'GPT Ù…ÙØªÙˆØ­ Ø§Ù„Ù…ØµØ¯Ø± â€” 20B',
    type: 'text',
    contextWindow: 131072,
    maxOutputTokens: 16384,
    description: 'Lighter OpenAI model. Good balance of speed and capability.',
    descriptionAr: 'Ù†Ù…ÙˆØ°Ø¬ OpenAI Ø®ÙÙŠÙ. ØªÙˆØ§Ø²Ù† Ø¬ÙŠØ¯ Ø¨ÙŠÙ† Ø§Ù„Ø³Ø±Ø¹Ø© ÙˆØ§Ù„Ù‚Ø¯Ø±Ø©.',
    speed: 'fast',
    quality: 'medium',
  },
  {
    id: 'openai/gpt-oss-safeguard-20b',
    name: 'GPT OSS Safeguard 20B',
    nameAr: 'GPT Ø­Ù…Ø§ÙŠØ© â€” 20B',
    type: 'text',
    contextWindow: 131072,
    maxOutputTokens: 16384,
    description: 'Safety-focused model. Good for content moderation tasks.',
    descriptionAr: 'Ù†Ù…ÙˆØ°Ø¬ ÙŠØ±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ø³Ù„Ø§Ù…Ø©. Ù…Ù†Ø§Ø³Ø¨ Ù„Ù…Ù‡Ø§Ù… Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰.',
    speed: 'fast',
    quality: 'medium',
  },
  {
    id: 'qwen/qwen3-32b',
    name: 'Qwen 3 32B',
    nameAr: 'ÙƒÙˆÙŠÙ† 3 â€” 32B',
    type: 'text',
    contextWindow: 131072,
    maxOutputTokens: 16384,
    description: 'Alibaba Qwen3. Strong multilingual & coding capabilities.',
    descriptionAr: 'Ù†Ù…ÙˆØ°Ø¬ Qwen3 Ù…Ù† Ø¹Ù„ÙŠ Ø¨Ø§Ø¨Ø§. Ù‚ÙˆÙŠ ÙÙŠ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø© ÙˆØ§Ù„Ø¨Ø±Ù…Ø¬Ø©.',
    speed: 'fast',
    quality: 'high',
  },
  {
    id: 'moonshotai/kimi-k2-instruct-0905',
    name: 'Kimi K2 Instruct',
    nameAr: 'ÙƒÙŠÙ…ÙŠ K2',
    type: 'text',
    contextWindow: 131072,
    maxOutputTokens: 16384,
    description: 'Moonshot AI Kimi. Excellent instruction following.',
    descriptionAr: 'Ù†Ù…ÙˆØ°Ø¬ ÙƒÙŠÙ…ÙŠ Ù…Ù† Moonshot. Ù…Ù…ØªØ§Ø² ÙÙŠ Ø§ØªØ¨Ø§Ø¹ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª.',
    speed: 'fast',
    quality: 'high',
  },

  // â•â•â• Compound AI Models â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  {
    id: 'groq/compound',
    name: 'Groq Compound',
    nameAr: 'Ø¬Ø±ÙˆÙƒ Ù…Ø±ÙƒØ¨',
    type: 'compound',
    contextWindow: 131072,
    maxOutputTokens: 32768,
    description: 'Multi-step reasoning with tool use. Best for complex workflows.',
    descriptionAr: 'ØªÙÙƒÙŠØ± Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ù…Ø¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø¯ÙˆØ§Øª. Ø§Ù„Ø£ÙØ¶Ù„ Ù„Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ù…Ø¹Ù‚Ø¯.',
    speed: 'medium',
    quality: 'high',
    recommended: true,
  },
  {
    id: 'groq/compound-mini',
    name: 'Groq Compound Mini',
    nameAr: 'Ø¬Ø±ÙˆÙƒ Ù…Ø±ÙƒØ¨ ØµØºÙŠØ±',
    type: 'compound',
    contextWindow: 131072,
    maxOutputTokens: 16384,
    description: 'Lightweight compound model. Faster multi-step reasoning.',
    descriptionAr: 'Ù†Ù…ÙˆØ°Ø¬ Ù…Ø±ÙƒØ¨ Ø®ÙÙŠÙ. ØªÙÙƒÙŠØ± Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø£Ø³Ø±Ø¹.',
    speed: 'fast',
    quality: 'medium',
  },

  // â•â•â• Audio: Speech-to-Text â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  {
    id: 'whisper-large-v3',
    name: 'Whisper Large V3',
    nameAr: 'ÙˆÙŠØ³Ø¨Ø± ÙƒØ¨ÙŠØ± V3',
    type: 'stt',
    contextWindow: 0,
    maxOutputTokens: 0,
    description: 'OpenAI Whisper. High-accuracy speech-to-text in 99 languages.',
    descriptionAr: 'ÙˆÙŠØ³Ø¨Ø± Ù…Ù† OpenAI. ØªØ­ÙˆÙŠÙ„ ØµÙˆØª Ù„Ù†Øµ Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© ÙÙŠ 99 Ù„ØºØ©.',
    speed: 'medium',
    quality: 'high',
  },
  {
    id: 'whisper-large-v3-turbo',
    name: 'Whisper Large V3 Turbo',
    nameAr: 'ÙˆÙŠØ³Ø¨Ø± ÙƒØ¨ÙŠØ± V3 ØªÙˆØ±Ø¨Ùˆ',
    type: 'stt',
    contextWindow: 0,
    maxOutputTokens: 0,
    description: 'Faster Whisper variant. Slightly lower accuracy, much faster.',
    descriptionAr: 'Ù†Ø³Ø®Ø© Ø£Ø³Ø±Ø¹ Ù…Ù† ÙˆÙŠØ³Ø¨Ø±. Ø¯Ù‚Ø© Ø£Ù‚Ù„ Ù‚Ù„ÙŠÙ„Ø§Ù‹ØŒ Ø£Ø³Ø±Ø¹ Ø¨ÙƒØ«ÙŠØ±.',
    speed: 'fast',
    quality: 'medium',
  },

  // â•â•â• Audio: Text-to-Speech â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  {
    id: 'canopylabs/orpheus-arabic-saudi',
    name: 'Orpheus Arabic Saudi',
    nameAr: 'Ø£ÙˆØ±ÙÙŠÙˆØ³ Ø¹Ø±Ø¨ÙŠ Ø³Ø¹ÙˆØ¯ÙŠ',
    type: 'tts',
    contextWindow: 0,
    maxOutputTokens: 0,
    description: 'Arabic TTS with Saudi dialect. Natural-sounding Arabic speech.',
    descriptionAr: 'ØªØ­ÙˆÙŠÙ„ Ù†Øµ Ù„ØµÙˆØª Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©. Ù†Ø·Ù‚ Ø¹Ø±Ø¨ÙŠ Ø·Ø¨ÙŠØ¹ÙŠ.',
    speed: 'fast',
    quality: 'high',
  },
];

// â”€â”€â”€ Grouped Models â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export const MODEL_GROUPS: ModelGroup[] = [
  {
    type: 'text',
    label: 'Text Generation',
    labelAr: 'ðŸ§  ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†ØµÙˆØµ',
    icon: 'ðŸ§ ',
    models: GROQ_MODELS.filter(m => m.type === 'text'),
  },
  {
    type: 'compound',
    label: 'Compound AI',
    labelAr: 'ðŸ”— Ø°ÙƒØ§Ø¡ Ù…Ø±ÙƒØ¨',
    icon: 'ðŸ”—',
    models: GROQ_MODELS.filter(m => m.type === 'compound'),
  },
  {
    type: 'stt',
    label: 'Speech-to-Text',
    labelAr: 'ðŸŽ¤ ØµÙˆØª â†’ Ù†Øµ',
    icon: 'ðŸŽ¤',
    models: GROQ_MODELS.filter(m => m.type === 'stt'),
  },
  {
    type: 'tts',
    label: 'Text-to-Speech',
    labelAr: 'ðŸ”Š Ù†Øµ â†’ ØµÙˆØª',
    icon: 'ðŸ”Š',
    models: GROQ_MODELS.filter(m => m.type === 'tts'),
  },
];

// â”€â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export function getModelById(id: string): GroqModel | undefined {
  return GROQ_MODELS.find(m => m.id === id);
}

export function getTextModels(): GroqModel[] {
  return GROQ_MODELS.filter(m => m.type === 'text' || m.type === 'compound');
}

export function getRecommendedModels(): GroqModel[] {
  return GROQ_MODELS.filter(m => m.recommended);
}

export function getDefaultModel(): GroqModel {
  return GROQ_MODELS.find(m => m.id === 'llama-3.3-70b-versatile')!;
}
